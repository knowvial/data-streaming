# Handling streaming data with Kafka and Spark Streaming
This repo provides some sample resources to introduce Kafka and Spark Streaming for beginners.

## Lab #1 (Kafka)
1. Install Kafka on Linux or on Windows - https://tinyurl.com/s98fbtq
2. Learn some basic Kafka CLI commands - https://tinyurl.com/uastytv (Linux / Mac) or https://tinyurl.com/tago627 (Windows)

## Lab #2 (Kafka)
* Write your first Kafka Producer / Consumer to get tweets from Twitter and write to a file - Instructions on page https://github.com/rbotla/data-streaming/tree/master/kafka/producer-consumer.

## Lab #3 (Kafka)
* Write your first Kafka Connect to get tweets and produce to a Kafka topic - Instructions on page https://github.com/rbotla/data-streaming/tree/master/kafka/connect.

## Lab #4 (Spark Streaming)
* Wordcount on a stream of lines entered on a Netcat socket - 

## Lab #5 (Spark Streaming)
* Snapshot view of data from file streaming
* Aggregates on file streaming over a timed interval

## Lab #6 (Kafka + Spark Streaming)
* Twitter sentiment analaysis for tweets ingested through Kafka

## Optional
The instructions for running the sample code are written for Google Cloud Platform.

* Create a Free Tier GCP account - follow instructions at https://cloud.google.com/free
* Create a VM
* Install gcloud - https://cloud.google.com/sdk/install

```
sudo apt-get update && sudo apt-get install google-cloud-sdk
```

## Kafka
* Install Kafka and run CLI commands - instructions at https://tinyurl.com/uastytv
* Python sample code for Producer / Consumer - https://github.com/rbotla/data-streaming/tree/master/kafka/producer-consumer/python
* Python sample code for Kafka Connect - https://github.com/rbotla/data-streaming/tree/master/kafka/connect

## Spark Streaming
* Install Spark - instructions at https://tinyurl.com/v2vqfwl
* Run Spark Streaming examples - instructions at 

Other:

```
sudo apt update
sudo apt install git
```