# Handling streaming data with Kafka and Spark Streaming
This repo provides some sample resources to introduce Kafka and Spark Streaming for beginners.

## Lab #1 (Kafka)
1. Install Kafka on Linux or on Windows - https://tinyurl.com/s98fbtq
2. Learn some basic Kafka CLI commands - https://tinyurl.com/uastytv (Linux / Mac) or https://tinyurl.com/tago627 (Windows)

## Lab #2 (Kafka)
* Write Kafka Producer and Consumer programs to get tweets from Twitter, post to a Kafka topic, Read from Kafka topic and write to a file - [Windows instructions](https://github.com/rbotla/data-streaming/tree/master/kafka/producer-consumer/python#instructions-on-windows) or [Linkux / Mac instructions](https://github.com/rbotla/data-streaming/tree/master/kafka/producer-consumer/python#instructions-on-linux---debian-9).

## Lab #3 (Kafka)
* Write Kafka Connect program to get tweets and send to a Kafka topic - [Windows instructions](https://github.com/rbotla/data-streaming/tree/master/kafka/connect#instructions-on-windows) Instructions on page [Linkux / Mac instructions](https://github.com/rbotla/data-streaming/tree/master/kafka/connect#instructions-on-linux---debian-9).

## Lab #4 (Spark Streaming)
* Wordcount on a stream of lines entered on a Netcat socket - [instructions and code](https://github.com/rbotla/data-streaming/tree/master/spark-streaming#word-count-with-structured-streaming)

## Lab #5 (Spark Streaming)
* Aggregates on file streaming over a timed interval - [instructions and code](https://github.com/rbotla/data-streaming/tree/master/spark-streaming#sales-by-state-aggregation)

## Lab #6 (Kafka + Spark Streaming)
* Twitter sentiment analaysis for tweets ingested through Kafka [instructions and code](https://github.com/rbotla/data-streaming/tree/master/spark-streaming/kafka)
